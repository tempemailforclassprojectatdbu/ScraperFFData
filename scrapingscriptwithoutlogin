import requests
from bs4 import BeautifulSoup
import csv
import os

# URL of the target page
URL = "https://www.fantasypros.com/nfl/rankings/waiver-wire-half-point-ppr-overall.php"

# Output file name
OUTPUT_FILE = "Waiver_Wire_Rankings.csv"

def scrape_table(url, output_file):
    """Scrapes the waiver wire rankings table from the FantasyPros website and saves it as a CSV file."""
    try:
        # Step 1: Send a GET request to fetch the webpage content
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
        }
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # Ensure the request was successful

        # Step 2: Parse the webpage content with BeautifulSoup
        soup = BeautifulSoup(response.text, 'html.parser')

        # Step 3: Locate the table
        table = soup.find("table", {"class": "table"})  # Update the class if the table changes
        if not table:
            raise ValueError("Could not find the table on the page.")

        # Step 4: Extract table headers
        headers = [header.text.strip() for header in table.find_all("th")]

        # Step 5: Extract table rows
        rows = []
        for row in table.find("tbody").find_all("tr"):
            cells = [cell.text.strip() for cell in row.find_all("td")]
            rows.append(cells)

        # Step 6: Save the data to a CSV file
        with open(output_file, mode="w", newline="", encoding="utf-8") as file:
            writer = csv.writer(file)
            writer.writerow(headers)  # Write headers
            writer.writerows(rows)   # Write rows

        print(f"Data successfully scraped and saved to {output_file}")

    except Exception as e:
        print(f"An error occurred: {e}")

# Main script execution
if __name__ == "__main__":
    scrape_table(URL, OUTPUT_FILE)
